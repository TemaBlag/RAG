{"cells":[{"cell_type":"markdown","id":"41ce62a8-251f-4f9e-b375-e93a5861c3fe","metadata":{"id":"41ce62a8-251f-4f9e-b375-e93a5861c3fe"},"source":["# Rag From Scratch: Overview\n","\n","These notebooks walk through the process of building RAG app(s) from scratch.\n","\n","They will build towards a broader understanding of the RAG langscape\n","## Enviornment\n","\n","`(1) Packages`"]},{"cell_type":"code","execution_count":1,"id":"3a88555a-53a5-4ab8-ba3d-e6dd3a26c71a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63823,"status":"ok","timestamp":1727331423300,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"3a88555a-53a5-4ab8-ba3d-e6dd3a26c71a","outputId":"18424106-2106-434f-c792-d908767ca8e7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_community\n","  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n","Collecting tiktoken\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n","Collecting langchainhub\n","  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n","Collecting chromadb\n","  Downloading chromadb-0.5.9-py3-none-any.whl.metadata (6.8 kB)\n","Collecting langchain\n","  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: PyYAML\u003e=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n","Requirement already satisfied: SQLAlchemy\u003c3,\u003e=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.35)\n","Requirement already satisfied: aiohttp\u003c4.0.0,\u003e=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n","Collecting dataclasses-json\u003c0.7,\u003e=0.5.7 (from langchain_community)\n","  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n","Collecting langchain-core\u003c0.4.0,\u003e=0.3.6 (from langchain_community)\n","  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n","Collecting langsmith\u003c0.2.0,\u003e=0.1.125 (from langchain_community)\n","  Downloading langsmith-0.1.128-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy\u003c2,\u003e=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n","Collecting pydantic-settings\u003c3.0.0,\u003e=2.4.0 (from langchain_community)\n","  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n","Requirement already satisfied: requests\u003c3,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n","Collecting tenacity!=8.4.0,\u003c9.0.0,\u003e=8.1.0 (from langchain_community)\n","  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: regex\u003e=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n","Collecting openai\u003c2.0.0,\u003e=1.40.0 (from langchain-openai)\n","  Downloading openai-1.48.0-py3-none-any.whl.metadata (24 kB)\n","Requirement already satisfied: packaging\u003c25,\u003e=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n","Collecting types-requests\u003c3.0.0.0,\u003e=2.31.0.2 (from langchainhub)\n","  Downloading types_requests-2.32.0.20240914-py3-none-any.whl.metadata (1.9 kB)\n","Requirement already satisfied: build\u003e=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.2)\n","Requirement already satisfied: pydantic\u003e=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.9.2)\n","Collecting chroma-hnswlib==0.7.6 (from chromadb)\n","  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n","Collecting fastapi\u003e=0.95.2 (from chromadb)\n","  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n","Collecting uvicorn\u003e=0.18.3 (from uvicorn[standard]\u003e=0.18.3-\u003echromadb)\n","  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n","Collecting posthog\u003e=2.4.0 (from chromadb)\n","  Downloading posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n","Requirement already satisfied: typing-extensions\u003e=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n","Collecting onnxruntime\u003e=1.14.1 (from chromadb)\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Collecting opentelemetry-api\u003e=1.2.0 (from chromadb)\n","  Downloading opentelemetry_api-1.27.0-py3-none-any.whl.metadata (1.4 kB)\n","Collecting opentelemetry-exporter-otlp-proto-grpc\u003e=1.2.0 (from chromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-fastapi\u003e=0.41b0 (from chromadb)\n","  Downloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl.metadata (2.1 kB)\n","Collecting opentelemetry-sdk\u003e=1.2.0 (from chromadb)\n","  Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: tokenizers\u003e=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n","Collecting pypika\u003e=0.48.9 (from chromadb)\n","  Downloading PyPika-0.48.9.tar.gz (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm\u003e=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n","Collecting overrides\u003e=7.3.1 (from chromadb)\n","  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n","Requirement already satisfied: grpcio\u003e=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n","Collecting bcrypt\u003e=4.0.1 (from chromadb)\n","  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n","Requirement already satisfied: typer\u003e=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n","Collecting kubernetes\u003e=28.1.0 (from chromadb)\n","  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting mmh3\u003e=4.0.1 (from chromadb)\n","  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n","Collecting orjson\u003e=3.9.12 (from chromadb)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx\u003e=0.27.0 (from chromadb)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: rich\u003e=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.8.1)\n","Requirement already satisfied: async-timeout\u003c5.0.0,\u003e=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n","Collecting langchain-text-splitters\u003c0.4.0,\u003e=0.3.0 (from langchain)\n","  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: aiohappyeyeballs\u003e=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (2.4.0)\n","Requirement already satisfied: aiosignal\u003e=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (1.3.1)\n","Requirement already satisfied: attrs\u003e=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (24.2.0)\n","Requirement already satisfied: frozenlist\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (1.4.1)\n","Requirement already satisfied: multidict\u003c7.0,\u003e=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (6.1.0)\n","Requirement already satisfied: yarl\u003c2.0,\u003e=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp\u003c4.0.0,\u003e=3.8.3-\u003elangchain_community) (1.11.1)\n","Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build\u003e=1.0.3-\u003echromadb) (1.1.0)\n","Requirement already satisfied: tomli\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build\u003e=1.0.3-\u003echromadb) (2.0.1)\n","Collecting marshmallow\u003c4.0.0,\u003e=3.18.0 (from dataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain_community)\n","  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting typing-inspect\u003c1,\u003e=0.4.0 (from dataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain_community)\n","  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n","Collecting starlette\u003c0.39.0,\u003e=0.37.2 (from fastapi\u003e=0.95.2-\u003echromadb)\n","  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.27.0-\u003echromadb) (3.7.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.27.0-\u003echromadb) (2024.8.30)\n","Collecting httpcore==1.* (from httpx\u003e=0.27.0-\u003echromadb)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.27.0-\u003echromadb) (3.10)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx\u003e=0.27.0-\u003echromadb) (1.3.1)\n","Collecting h11\u003c0.15,\u003e=0.13 (from httpcore==1.*-\u003ehttpx\u003e=0.27.0-\u003echromadb)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: six\u003e=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (1.16.0)\n","Requirement already satisfied: python-dateutil\u003e=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (2.8.2)\n","Requirement already satisfied: google-auth\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (2.27.0)\n","Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,\u003e=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (1.8.0)\n","Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (1.3.1)\n","Requirement already satisfied: oauthlib\u003e=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (3.2.2)\n","Requirement already satisfied: urllib3\u003e=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes\u003e=28.1.0-\u003echromadb) (2.2.3)\n","Collecting durationpy\u003e=0.7 (from kubernetes\u003e=28.1.0-\u003echromadb)\n","  Downloading durationpy-0.7.tar.gz (3.2 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting jsonpatch\u003c2.0,\u003e=1.33 (from langchain-core\u003c0.4.0,\u003e=0.3.6-\u003elangchain_community)\n","  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n","Collecting coloredlogs (from onnxruntime\u003e=1.14.1-\u003echromadb)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime\u003e=1.14.1-\u003echromadb) (24.3.25)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime\u003e=1.14.1-\u003echromadb) (3.20.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime\u003e=1.14.1-\u003echromadb) (1.13.3)\n","Requirement already satisfied: distro\u003c2,\u003e=1.7.0 in /usr/lib/python3/dist-packages (from openai\u003c2.0.0,\u003e=1.40.0-\u003elangchain-openai) (1.7.0)\n","Collecting jiter\u003c1,\u003e=0.4.0 (from openai\u003c2.0.0,\u003e=1.40.0-\u003elangchain-openai)\n","  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting deprecated\u003e=1.2.6 (from opentelemetry-api\u003e=1.2.0-\u003echromadb)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n","Collecting importlib-metadata\u003c=8.4.0,\u003e=6.0 (from opentelemetry-api\u003e=1.2.0-\u003echromadb)\n","  Downloading importlib_metadata-8.4.0-py3-none-any.whl.metadata (4.7 kB)\n","Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc\u003e=1.2.0-\u003echromadb) (1.65.0)\n","Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc\u003e=1.2.0-\u003echromadb)\n","  Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc\u003e=1.2.0-\u003echromadb)\n","  Downloading opentelemetry_proto-1.27.0-py3-none-any.whl.metadata (2.3 kB)\n","Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb)\n","  Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl.metadata (2.0 kB)\n","Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb)\n","  Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl.metadata (6.1 kB)\n","Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb)\n","  Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl.metadata (2.4 kB)\n","Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb)\n","  Downloading opentelemetry_util_http-0.48b0-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: setuptools\u003e=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0-\u003eopentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb) (71.0.4)\n","Requirement already satisfied: wrapt\u003c2.0.0,\u003e=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0-\u003eopentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb) (1.16.0)\n","Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0-\u003eopentelemetry-instrumentation-fastapi\u003e=0.41b0-\u003echromadb)\n","  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n","Collecting monotonic\u003e=1.5 (from posthog\u003e=2.4.0-\u003echromadb)\n","  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting backoff\u003e=1.10.0 (from posthog\u003e=2.4.0-\u003echromadb)\n","  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=1.9-\u003echromadb) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003e=1.9-\u003echromadb) (2.23.4)\n","Collecting python-dotenv\u003e=0.21.0 (from pydantic-settings\u003c3.0.0,\u003e=2.4.0-\u003elangchain_community)\n","  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3,\u003e=2-\u003elangchain_community) (3.3.2)\n","Requirement already satisfied: markdown-it-py\u003e=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003e=10.11.0-\u003echromadb) (3.0.0)\n","Requirement already satisfied: pygments\u003c3.0.0,\u003e=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich\u003e=10.11.0-\u003echromadb) (2.18.0)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy\u003c3,\u003e=1.4-\u003elangchain_community) (3.1.1)\n","Requirement already satisfied: huggingface-hub\u003c1.0,\u003e=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers\u003e=0.13.2-\u003echromadb) (0.24.7)\n","Requirement already satisfied: click\u003e=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer\u003e=0.9.0-\u003echromadb) (8.1.7)\n","Requirement already satisfied: shellingham\u003e=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer\u003e=0.9.0-\u003echromadb) (1.5.4)\n","Collecting httptools\u003e=0.5.0 (from uvicorn[standard]\u003e=0.18.3-\u003echromadb)\n","  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting uvloop!=0.15.0,!=0.15.1,\u003e=0.14.0 (from uvicorn[standard]\u003e=0.18.3-\u003echromadb)\n","  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting watchfiles\u003e=0.13 (from uvicorn[standard]\u003e=0.18.3-\u003echromadb)\n","  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Collecting websockets\u003e=10.4 (from uvicorn[standard]\u003e=0.18.3-\u003echromadb)\n","  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio-\u003ehttpx\u003e=0.27.0-\u003echromadb) (1.2.2)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003e=1.0.1-\u003ekubernetes\u003e=28.1.0-\u003echromadb) (5.5.0)\n","Requirement already satisfied: pyasn1-modules\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003e=1.0.1-\u003ekubernetes\u003e=28.1.0-\u003echromadb) (0.4.1)\n","Requirement already satisfied: rsa\u003c5,\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003e=1.0.1-\u003ekubernetes\u003e=28.1.0-\u003echromadb) (4.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers\u003e=0.13.2-\u003echromadb) (3.16.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003c1.0,\u003e=0.16.4-\u003etokenizers\u003e=0.13.2-\u003echromadb) (2024.6.1)\n","Requirement already satisfied: zipp\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata\u003c=8.4.0,\u003e=6.0-\u003eopentelemetry-api\u003e=1.2.0-\u003echromadb) (3.20.2)\n","Collecting jsonpointer\u003e=1.9 (from jsonpatch\u003c2.0,\u003e=1.33-\u003elangchain-core\u003c0.4.0,\u003e=0.3.6-\u003elangchain_community)\n","  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py\u003e=2.2.0-\u003erich\u003e=10.11.0-\u003echromadb) (0.1.2)\n","Collecting mypy-extensions\u003e=0.3.0 (from typing-inspect\u003c1,\u003e=0.4.0-\u003edataclasses-json\u003c0.7,\u003e=0.5.7-\u003elangchain_community)\n","  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting humanfriendly\u003e=9.1 (from coloredlogs-\u003eonnxruntime\u003e=1.14.1-\u003echromadb)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003eonnxruntime\u003e=1.14.1-\u003echromadb) (1.3.0)\n","Requirement already satisfied: pyasn1\u003c0.7.0,\u003e=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules\u003e=0.2.1-\u003egoogle-auth\u003e=1.0.1-\u003ekubernetes\u003e=28.1.0-\u003echromadb) (0.6.1)\n","Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n","Downloading chromadb-0.5.9-py3-none-any.whl (602 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.5/602.5 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n","Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.9/399.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n","Downloading langsmith-0.1.128-py3-none-any.whl (292 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.48.0-py3-none-any.whl (376 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m376.1/376.1 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n","Downloading opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n","Downloading opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n","Downloading opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n","Downloading opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n","Downloading opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n","Downloading opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n","Downloading posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n","Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n","Downloading types_requests-2.32.0.20240914-py3-none-any.whl (15 kB)\n","Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n","Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n","Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n","Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n","Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n","Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n","Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n","Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n","Building wheels for collected packages: pypika, durationpy\n","  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=45a76aa9044aad139aae137784a7b99d7374e135d3fd594323a5b9b88fb6b8b0\n","  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n","  Building wheel for durationpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for durationpy: filename=durationpy-0.7-py3-none-any.whl size=3462 sha256=a6559a5e1500161cde0e378e9d704572b0776cbdc6253f1678a54718eb4364a5\n","  Stored in directory: /root/.cache/pip/wheels/a2/52/58/701659d0f7467c85c273d8d06d8f74f2646ee7da4145ce77b5\n","Successfully built pypika durationpy\n","Installing collected packages: pypika, monotonic, durationpy, websockets, uvloop, types-requests, tenacity, python-dotenv, overrides, orjson, opentelemetry-util-http, opentelemetry-proto, mypy-extensions, mmh3, marshmallow, jsonpointer, jiter, importlib-metadata, humanfriendly, httptools, h11, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, langchainhub, jsonpatch, httpcore, coloredlogs, pydantic-settings, opentelemetry-semantic-conventions, opentelemetry-instrumentation, onnxruntime, kubernetes, httpx, fastapi, dataclasses-json, opentelemetry-sdk, opentelemetry-instrumentation-asgi, openai, langsmith, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-core, langchain-text-splitters, langchain-openai, chromadb, langchain, langchain_community\n","  Attempting uninstall: tenacity\n","    Found existing installation: tenacity 9.0.0\n","    Uninstalling tenacity-9.0.0:\n","      Successfully uninstalled tenacity-9.0.0\n","  Attempting uninstall: importlib-metadata\n","    Found existing installation: importlib_metadata 8.5.0\n","    Uninstalling importlib_metadata-8.5.0:\n","      Successfully uninstalled importlib_metadata-8.5.0\n","Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.9 coloredlogs-15.0.1 dataclasses-json-0.6.7 deprecated-1.2.14 durationpy-0.7 fastapi-0.115.0 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.2 humanfriendly-10.0 importlib-metadata-8.4.0 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 kubernetes-31.0.0 langchain-0.3.1 langchain-core-0.3.6 langchain-openai-0.2.0 langchain-text-splitters-0.3.0 langchain_community-0.3.1 langchainhub-0.1.21 langsmith-0.1.128 marshmallow-3.22.0 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.19.2 openai-1.48.0 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 posthog-3.6.6 pydantic-settings-2.5.2 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.38.6 tenacity-8.5.0 tiktoken-0.7.0 types-requests-2.32.0.20240914 typing-inspect-0.9.0 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.1\n"]}],"source":["! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain"]},{"cell_type":"markdown","id":"75a8ab66-8477-429f-bbbe-ba439322d085","metadata":{"id":"75a8ab66-8477-429f-bbbe-ba439322d085"},"source":["`(2) LangSmith`\n","\n","https://docs.smith.langchain.com/"]},{"cell_type":"code","execution_count":2,"id":"b76f68a8-4745-4377-8057-6090b87377d1","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1727331423300,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"b76f68a8-4745-4377-8057-6090b87377d1"},"outputs":[],"source":["import os\n","os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n","os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n","os.environ['LANGCHAIN_API_KEY'] = \"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\""]},{"cell_type":"markdown","id":"f8eb312d-8a07-4df3-8462-72ac526715f7","metadata":{"id":"f8eb312d-8a07-4df3-8462-72ac526715f7"},"source":["`(3) API Keys`"]},{"cell_type":"code","execution_count":3,"id":"0THtNa3XAVZL","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8363,"status":"ok","timestamp":1727331431659,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"0THtNa3XAVZL","outputId":"6d47b35c-34c5-48cf-b395-10bf3d44a73b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_huggingface\n","  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: huggingface-hub\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.24.7)\n","Requirement already satisfied: langchain-core\u003c0.4,\u003e=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.3.6)\n","Collecting sentence-transformers\u003e=2.6.0 (from langchain_huggingface)\n","  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: tokenizers\u003e=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (0.19.1)\n","Requirement already satisfied: transformers\u003e=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain_huggingface) (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (3.16.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (2024.6.1)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (24.1)\n","Requirement already satisfied: pyyaml\u003e=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (6.0.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (2.32.3)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (4.66.5)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (4.12.2)\n","Requirement already satisfied: jsonpatch\u003c2.0,\u003e=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (1.33)\n","Requirement already satisfied: langsmith\u003c0.2.0,\u003e=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (0.1.128)\n","Requirement already satisfied: pydantic\u003c3.0.0,\u003e=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (2.9.2)\n","Requirement already satisfied: tenacity!=8.4.0,\u003c9.0.0,\u003e=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (8.5.0)\n","Requirement already satisfied: torch\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (2.4.1+cu121)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (1.5.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (1.13.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (10.4.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers\u003e=4.39.0-\u003elangchain_huggingface) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers\u003e=4.39.0-\u003elangchain_huggingface) (2024.9.11)\n","Requirement already satisfied: safetensors\u003e=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers\u003e=4.39.0-\u003elangchain_huggingface) (0.4.5)\n","Requirement already satisfied: jsonpointer\u003e=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch\u003c2.0,\u003e=1.33-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (3.0.0)\n","Requirement already satisfied: httpx\u003c1,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (0.27.2)\n","Requirement already satisfied: orjson\u003c4.0.0,\u003e=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (3.10.7)\n","Requirement already satisfied: annotated-types\u003e=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003c3.0.0,\u003e=2.5.2-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic\u003c3.0.0,\u003e=2.5.2-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (2.23.4)\n","Requirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (2.2.3)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-\u003ehuggingface-hub\u003e=0.23.0-\u003elangchain_huggingface) (2024.8.30)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch\u003e=1.11.0-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (3.1.4)\n","Requirement already satisfied: joblib\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl\u003e=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (3.5.0)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (1.0.5)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (1.3.1)\n","Requirement already satisfied: h11\u003c0.15,\u003e=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*-\u003ehttpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (0.14.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-\u003etorch\u003e=1.11.0-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (2.1.5)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-\u003etorch\u003e=1.11.0-\u003esentence-transformers\u003e=2.6.0-\u003elangchain_huggingface) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio-\u003ehttpx\u003c1,\u003e=0.23.0-\u003elangsmith\u003c0.2.0,\u003e=0.1.125-\u003elangchain-core\u003c0.4,\u003e=0.3.0-\u003elangchain_huggingface) (1.2.2)\n","Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n","Downloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentence-transformers, langchain_huggingface\n","Successfully installed langchain_huggingface-0.1.0 sentence-transformers-3.1.1\n"]}],"source":["! pip install langchain_huggingface"]},{"cell_type":"code","execution_count":4,"id":"R1E_vTdgbTvX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17377,"status":"ok","timestamp":1727331449026,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"R1E_vTdgbTvX","outputId":"ad9333e9-dcad-4ea4-ce5b-b86474b61239"},"outputs":[{"name":"stdout","output_type":"stream","text":["Enter your token: ··········\n"]}],"source":["import getpass\n","import os\n","\n","if not os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"):\n","    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your token: \")"]},{"cell_type":"markdown","id":"1eae0ab7-d43b-43e0-8b99-6122a636fe0c","metadata":{"id":"1eae0ab7-d43b-43e0-8b99-6122a636fe0c"},"source":["## Part 1: Overview\n","\n","[RAG quickstart](https://python.langchain.com/docs/use_cases/question_answering/quickstart)"]},{"cell_type":"code","execution_count":null,"id":"c5wqiQBQRTI_","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"c5wqiQBQRTI_"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a92cbfb5c68e4ea8b53e0475f220a4cb","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/349 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee262314938846ecbc879f5a76858efd","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79a7d654fe584073801abe52af3de873","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/10.7k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ac78c2326934cbb873a8386d2bc1e2f","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"19171ff0d3ed455abceed6bc68699c40","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/612 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ec9d567cb07849c29f2a7162af124ab7","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5137c410172d47a8a1a7d4918d35c555","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/350 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"18b6154f9ff04c51bdedb53313425d98","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb2a8c379dc444f78cfa3903320caac9","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c3624f050584f9e9c772b531f9e7b35","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1dba4c937d6b4bd19b8d18c3564e3d94","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"abc134756ca949bf860ee2105c0d4f2f","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.43k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"05e14c07201d420a93905d2aa2eb9fc4","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/493k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b8c8bf54dde4812a45404bca80cd8eb","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.80M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f17e9df58304838a0f8943966cb350a","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/42.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ebf1d3a031545aba42e605cf843b305","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/168 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import bs4 # web scraping(part of BeautifulSoup)\n","from langchain import hub # manages prompts for various tasks\n","from langchain.text_splitter import RecursiveCharacterTextSplitter # splitter\n","from langchain_community.document_loaders import WebBaseLoader # loading web-based documents\n","from langchain_community.vectorstores import Chroma # vector store, allows you to efficiently search for similar documents\n","from langchain_core.output_parsers import StrOutputParser # process the output\n","from langchain_core.runnables import RunnablePassthrough # class that serves as a placeholder for tasks where no transformation is needed.\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline #  model responsible for generating text\n","from langchain_huggingface import HuggingFaceEmbeddings # generates vector embeddings for text\n","from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n","\n","#### INDEXING ####\n","\n","# Load Documents\n","loader = WebBaseLoader(\n","    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n","    bs_kwargs=dict(\n","        parse_only=bs4.SoupStrainer(\n","            class_=(\"post-content\", \"post-title\", \"post-header\")\n","        )\n","    ),\n",")\n","docs = loader.load()\n","\n","# Split\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(docs)\n","\n","# Embed\n","embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n","\n","\n","retriever = vectorstore.as_retriever()\n","\n","prompt = hub.pull(\"rlm/rag-prompt\")\n","\n","# LLM\n","llm = HuggingFaceEndpoint(\n","    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n","    task=\"text-generation\",\n","    max_new_tokens=512,\n","    do_sample=False,\n","    repetition_penalty=1.03,\n",")\n","\n","chat_model = ChatHuggingFace(llm=llm)"]},{"cell_type":"code","execution_count":null,"id":"fA4SmvWLabH7","metadata":{"colab":{"background_save":true},"id":"fA4SmvWLabH7"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Task Decomposition involves breaking down complex tasks into smaller, more manageable steps. This enables agents to better understand and plan for how to accomplish the task. CoT (chain of thought) and Tree of Thoughts are techniques used for task decomposition in LLM-powered autonomous agents. CoT transforms big tasks into smaller, simpler steps, and Tree of Thoughts explores multiple reasoning possibilities at each step. Task decomposition can be done through simple prompts, task-specific instructions,'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | chat_model\n","    | StrOutputParser()\n",")\n","\n","rag_chain.invoke(\"What is Task Decomposition?\")"]},{"cell_type":"markdown","id":"18e8e856-bafd-469e-b99a-11596b18aad4","metadata":{"id":"18e8e856-bafd-469e-b99a-11596b18aad4"},"source":["## Part 2: Indexing"]},{"cell_type":"code","execution_count":null,"id":"edd7beeb-21fa-4f4b-b8fa-5a4f70489a16","metadata":{"colab":{"background_save":true},"id":"edd7beeb-21fa-4f4b-b8fa-5a4f70489a16"},"outputs":[],"source":["# Documents\n","question = \"What kinds of pets do I like?\"\n","document = \"My favorite pet is a cat.\""]},{"cell_type":"markdown","id":"e0552ea4-935d-4dfa-bd2b-56d148e96304","metadata":{"id":"e0552ea4-935d-4dfa-bd2b-56d148e96304"},"source":["[Count tokens](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) considering [~4 char / token](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them)"]},{"cell_type":"code","execution_count":null,"id":"df119cca-1676-4caa-bad4-11805d69e616","metadata":{"colab":{"background_save":true},"id":"df119cca-1676-4caa-bad4-11805d69e616"},"outputs":[{"data":{"text/plain":["8"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import tiktoken\n","\n","def num_tokens_from_string(string: str, encoding_name: str) -\u003e int:\n","    \"\"\"Returns the number of tokens in a text string.\"\"\"\n","    encoding = tiktoken.get_encoding(encoding_name)\n","    num_tokens = len(encoding.encode(string))\n","    return num_tokens\n","\n","num_tokens_from_string(question, \"cl100k_base\")"]},{"cell_type":"markdown","id":"4f04fd74-829f-472c-a1bc-ec6521a0529f","metadata":{"id":"4f04fd74-829f-472c-a1bc-ec6521a0529f"},"source":["[Text embedding models](https://python.langchain.com/docs/integrations/text_embedding/openai)"]},{"cell_type":"code","execution_count":null,"id":"6bd98786-755d-4d49-ba97-30c5a623b74e","metadata":{"colab":{"background_save":true},"id":"6bd98786-755d-4d49-ba97-30c5a623b74e"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f44c164ecc84512921a23a67592c65e","version_major":2,"version_minor":0},"text/plain":["modules.json:   0%|          | 0.00/229 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"710a0c4045584f0db6c13e3a67d5db28","version_major":2,"version_minor":0},"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/122 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2dd1ca0233f4415aebd4c627b9708e7","version_major":2,"version_minor":0},"text/plain":["README.md:   0%|          | 0.00/3.73k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b7905915882c46a689016b8b90297521","version_major":2,"version_minor":0},"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0c0c78f348d94af88ac8f864c1c819be","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/629 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b9952f52554747bd869716cf83150572","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/90.9M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36cb612049684c43a008672467f1ff0c","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/314 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c84ee90af554491bb77415f87c41b720","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48218906a86e47c59519f97e8e54a2d3","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"779c4302aa6d4bdd8d696fab083ec546","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"339946299ae34e55bc6c3f9b4fb79646","version_major":2,"version_minor":0},"text/plain":["1_Pooling/config.json:   0%|          | 0.00/190 [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["384"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_huggingface import HuggingFaceEmbeddings\n","\n","embd = HuggingFaceEmbeddings(model_name=\"paraphrase-MiniLM-L6-v2\")\n","query_result = embd.embed_query(question)\n","document_result = embd.embed_query(document)\n","len(query_result)"]},{"cell_type":"markdown","id":"f5e0e35f-6861-4c5e-9301-04fd5408f8f8","metadata":{"id":"f5e0e35f-6861-4c5e-9301-04fd5408f8f8"},"source":["[Cosine similarity](https://platform.openai.com/docs/guides/embeddings/frequently-asked-questions) is reccomended (1 indicates identical) for OpenAI embeddings."]},{"cell_type":"code","execution_count":null,"id":"b8001998-b08c-4560-b124-bfa1fced8958","metadata":{"colab":{"background_save":true},"id":"b8001998-b08c-4560-b124-bfa1fced8958"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cosine Similarity: 0.6247256066130413\n"]}],"source":["import numpy as np\n","\n","def cosine_similarity(vec1, vec2):\n","    dot_product = np.dot(vec1, vec2)\n","    norm_vec1 = np.linalg.norm(vec1)\n","    norm_vec2 = np.linalg.norm(vec2)\n","    return dot_product / (norm_vec1 * norm_vec2)\n","\n","similarity = cosine_similarity(query_result, document_result)\n","print(\"Cosine Similarity:\", similarity)"]},{"cell_type":"markdown","id":"8aea73bc-98e3-4fdc-ba72-d190736bed20","metadata":{"id":"8aea73bc-98e3-4fdc-ba72-d190736bed20"},"source":["[Document Loaders](https://python.langchain.com/docs/integrations/document_loaders/)"]},{"cell_type":"code","execution_count":null,"id":"5778c31a-6138-4130-8865-31a08e82b9fb","metadata":{"colab":{"background_save":true},"id":"5778c31a-6138-4130-8865-31a08e82b9fb"},"outputs":[],"source":["#### INDEXING ####\n","\n","# Load blog\n","import bs4\n","from langchain_community.document_loaders import WebBaseLoader\n","loader = WebBaseLoader(\n","    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n","    bs_kwargs=dict(\n","        parse_only=bs4.SoupStrainer(\n","            class_=(\"post-content\", \"post-title\", \"post-header\")\n","        )\n","    ),\n",")\n","blog_docs = loader.load()"]},{"cell_type":"markdown","id":"798e731e-c6ff-46e3-a8bc-386832362af2","metadata":{"id":"798e731e-c6ff-46e3-a8bc-386832362af2"},"source":["[Splitter](https://python.langchain.com/docs/modules/data_connection/document_transformers/recursive_text_splitter)\n","\n","\u003e This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."]},{"cell_type":"code","execution_count":null,"id":"e668d339-3951-4662-8387-c3d296646906","metadata":{"colab":{"background_save":true},"id":"e668d339-3951-4662-8387-c3d296646906"},"outputs":[],"source":["# Split\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n","    chunk_size=300,\n","    chunk_overlap=50)\n","\n","# Make splits\n","splits = text_splitter.split_documents(blog_docs)"]},{"cell_type":"markdown","id":"427303a1-3ed4-430c-bfc7-cb3e48022f1d","metadata":{"id":"427303a1-3ed4-430c-bfc7-cb3e48022f1d"},"source":["[Vectorstores](https://python.langchain.com/docs/integrations/vectorstores/)"]},{"cell_type":"code","execution_count":null,"id":"baa90aaf-cc1b-46a1-9fba-cf20804dcb41","metadata":{"colab":{"background_save":true},"id":"baa90aaf-cc1b-46a1-9fba-cf20804dcb41"},"outputs":[],"source":["# Index\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import Chroma\n","\n","embeddings_model = HuggingFaceEmbeddings(model_name=\"paraphrase-MiniLM-L6-v2\")\n","vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings_model)\n","\n","retriever = vectorstore.as_retriever()"]},{"cell_type":"markdown","id":"ba890329-1411-4922-bd27-fe0490dd1208","metadata":{"id":"ba890329-1411-4922-bd27-fe0490dd1208"},"source":["## Part 3: Retrieval"]},{"cell_type":"code","execution_count":null,"id":"fafdada1-4c4e-41f8-ad1a-33861aae3930","metadata":{"id":"fafdada1-4c4e-41f8-ad1a-33861aae3930"},"outputs":[],"source":["# Index\n","from langchain_community.vectorstores import Chroma\n","vectorstore = Chroma.from_documents(documents=splits,\n","                                    embedding=embeddings_model)\n","\n","\n","retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # k shows count of neighbors"]},{"cell_type":"code","execution_count":null,"id":"57c2de7a-93e6-4072-bc5b-db6516f96dda","metadata":{"id":"57c2de7a-93e6-4072-bc5b-db6516f96dda"},"outputs":[],"source":["docs = retriever.get_relevant_documents(\"What is Task Decomposition?\")"]},{"cell_type":"code","execution_count":null,"id":"db96f877-60d3-4741-9846-e2903831583d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1727179800290,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"db96f877-60d3-4741-9846-e2903831583d","outputId":"d5aae725-13aa-4734-f2f2-dac9eca99770"},"outputs":[{"data":{"text/plain":["3"]},"execution_count":149,"metadata":{},"output_type":"execute_result"}],"source":["len(docs)"]},{"cell_type":"markdown","id":"beda1b07-7bd2-4f5b-8d44-1fc52f5d2ce2","metadata":{"id":"beda1b07-7bd2-4f5b-8d44-1fc52f5d2ce2"},"source":["## Part 4: Generation"]},{"cell_type":"code","execution_count":null,"id":"8beb6c14-5e18-43e7-9d04-59e3b8a81cc9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1727180142665,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"8beb6c14-5e18-43e7-9d04-59e3b8a81cc9","outputId":"81f7e493-b4c7-4ef6-b17d-b293c748b644"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"]},"execution_count":151,"metadata":{},"output_type":"execute_result"}],"source":["from langchain.prompts import ChatPromptTemplate\n","\n","# Prompt\n","template = \"\"\"Answer the question based only on the following context:\n","{context}\n","\n","Question: {question}\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template)\n","prompt"]},{"cell_type":"code","execution_count":null,"id":"nLrJKdZ79nhx","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":584,"status":"ok","timestamp":1727180213470,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"nLrJKdZ79nhx","outputId":"b4365aa2-51ef-4d3d-b053-681d725c76a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n","Token is valid (permission: write).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}],"source":["llm = HuggingFaceEndpoint(\n","    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n","    task=\"text-generation\",\n","    max_new_tokens=512,\n","    do_sample=False,\n","    repetition_penalty=1.03,\n",")\n","\n","chat_model = ChatHuggingFace(llm=llm)"]},{"cell_type":"code","execution_count":null,"id":"55d6629f-18ec-4372-a557-b254fbb1dd2d","metadata":{"id":"55d6629f-18ec-4372-a557-b254fbb1dd2d"},"outputs":[],"source":["# Chain\n","chain = prompt | chat_model"]},{"cell_type":"code","execution_count":null,"id":"94470770-8df4-4359-9504-ef6c8b3137ff","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2246,"status":"ok","timestamp":1727180220171,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"94470770-8df4-4359-9504-ef6c8b3137ff","outputId":"dee52b52-b229-49ae-87ba-98a280014055"},"outputs":[{"data":{"text/plain":["AIMessage(content='My training data does not provide a definition for Task Decomposition in the given context. However, based on the presented concepts, Task Decomposition might refer to the process of breaking down complex tasks or objectives into smaller, more manageable sub-tasks that can be completed by individual agents within the multi-agent system. These sub-tasks are interdependent and contribute to the overall achievement of the overarching goal or objective. Task Decomposition helps in coordinating the activities of multiple agents', additional_kwargs={}, response_metadata={'token_usage': ChatCompletionOutputUsage(completion_tokens=100, prompt_tokens=1100, total_tokens=1200), 'model': '', 'finish_reason': 'length'}, id='run-61ee9a58-86c0-4a72-8a54-78e338e925d2-0')"]},"execution_count":155,"metadata":{},"output_type":"execute_result"}],"source":["# Run\n","chain.invoke({\"context\":docs,\"question\":\"What is Task Decomposition?\"})"]},{"cell_type":"code","execution_count":null,"id":"65770e2d-3d5e-4371-abc9-0aeca9646885","metadata":{"id":"65770e2d-3d5e-4371-abc9-0aeca9646885"},"outputs":[],"source":["from langchain import hub\n","prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")"]},{"cell_type":"code","execution_count":null,"id":"f53e5840-0a0f-4428-a4a4-6922800aff89","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1727180350809,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"f53e5840-0a0f-4428-a4a4-6922800aff89","outputId":"59928f4a-a1aa-4ba6-8d99-ef261f14004e"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"]},"execution_count":157,"metadata":{},"output_type":"execute_result"}],"source":["prompt_hub_rag"]},{"cell_type":"markdown","id":"8ffe29a1-5527-419e-9f12-8a3061d12885","metadata":{"id":"8ffe29a1-5527-419e-9f12-8a3061d12885"},"source":["[RAG chains](https://python.langchain.com/docs/expression_language/get_started#rag-search-example)"]},{"cell_type":"code","execution_count":null,"id":"8208a8bc-c75f-4e8e-8601-680746cd6276","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"elapsed":465,"status":"ok","timestamp":1727180399316,"user":{"displayName":"Артём Благодарный","userId":"00231038645499551760"},"user_tz":-180},"id":"8208a8bc-c75f-4e8e-8601-680746cd6276","outputId":"6cbfcb82-c23b-4ca6-f6ee-a705d5b52581"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'My training data does not provide a definition for Task Decomposition in the given context. However, based on the presented concepts, Task Decomposition might refer to the process of breaking down complex tasks or objectives into smaller, more manageable sub-tasks that can be completed by individual agents within the multi-agent system. These sub-tasks are interdependent and contribute to the overall achievement of the overarching goal or objective. Task Decomposition helps in coordinating the activities of multiple agents'"]},"execution_count":159,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","\n","rag_chain = (\n","    {\"context\": retriever, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | chat_model\n","    | StrOutputParser()\n",")\n","\n","rag_chain.invoke(\"What is Task Decomposition?\")"]}],"metadata":{"colab":{"name":"","provenance":[{"file_id":"1C_Pgag0O-e5_qEgezbV_UFWPDSy3zMay","timestamp":1727181079500}],"version":""},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}